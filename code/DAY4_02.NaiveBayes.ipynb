{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:31:43.126551Z",
     "start_time": "2018-09-15T08:31:41.816183Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 댓글을 이용한 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:18:56.821546Z",
     "start_time": "2018-09-15T05:18:56.815008Z"
    }
   },
   "outputs": [],
   "source": [
    "# !bitsadmin /transfer get https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt %cd%\\ratings_train.txt\n",
    "# !bitsadmin /transfer get https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt %cd%\\ratings_test.txt    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  mac / linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:32:33.027854Z",
     "start_time": "2018-09-15T08:32:20.230256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-09-15 17:32:20--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
      "Resolving raw.githubusercontent.com... 151.101.72.133\n",
      "Connecting to raw.githubusercontent.com|151.101.72.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14628807 (14M) [text/plain]\n",
      "Saving to: ‘ratings_train.txt.1’\n",
      "\n",
      "ratings_train.txt.1  13%[=>                  ]   1.93M   406KB/s    eta 49s    ^C\n",
      "--2018-09-15 17:32:30--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
      "Resolving raw.githubusercontent.com... 151.101.72.133\n",
      "Connecting to raw.githubusercontent.com|151.101.72.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4893335 (4.7M) [text/plain]\n",
      "Saving to: ‘ratings_test.txt.1’\n",
      "\n",
      "ratings_test.txt.1    8%[>                   ] 407.17K   269KB/s               ^C\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
    "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:33:05.628260Z",
     "start_time": "2018-09-15T08:33:05.195964Z"
    }
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import numpy as np\n",
    "with codecs.open(\"ratings_train.txt\", encoding='utf-8') as f:\n",
    "    train = [line.split('\\t') for line in f.read().splitlines()]\n",
    "    train = train[1:]   # header 제외\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:33:07.218768Z",
     "start_time": "2018-09-15T08:33:07.033880Z"
    }
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"ratings_test.txt\", encoding='utf-8') as f:\n",
    "    test = [line.split('\\t') for line in f.read().splitlines()]\n",
    "    test = test[1:]   # header 제외\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나이브베이즈 모델을 이용한 감성 분석 (Sentiment Analysis)\n",
    "- 네이버 영화 리뷰\n",
    "    - 평점 3점 이상이면 긍정 / 3점 미만이면 부정\n",
    "- 사전확률 계산\n",
    "- likelihood 계산\n",
    "- 모델 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:33:14.953420Z",
     "start_time": "2018-09-15T08:33:14.946504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0'],\n",
       " ['3819312', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1'],\n",
       " ['10265843', '너무재밓었다그래서보는것을추천한다', '0']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:33:17.501565Z",
     "start_time": "2018-09-15T08:33:17.493467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['6270596', '굳 ㅋ', '1'],\n",
       " ['9274899', 'GDNTOPCLASSINTHECLUB', '0'],\n",
       " ['8544678', '뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아', '0']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 사전확률 계산\n",
    "- ## $ P(y = C_k) $\n",
    "    - 각 클래스 (C) 의 확률 계산\n",
    "        - 클래스별 비율을 계산하는 것임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:34:54.719518Z",
     "start_time": "2018-09-15T08:34:54.714347Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_target(data):\n",
    "    from collections import defaultdict\n",
    "    counts = defaultdict(int) ## value의 기본 자료형이 int인 dict\n",
    "    for i, row in enumerate(data):\n",
    "        sentiment = row[2] # 긍정인지, 부정인지\n",
    "        counts[sentiment] += 1\n",
    "            \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:34:55.201584Z",
     "start_time": "2018-09-15T08:34:55.114340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'0': 75173, '1': 74827})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_target(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:35:05.092593Z",
     "start_time": "2018-09-15T08:35:05.085212Z"
    }
   },
   "outputs": [],
   "source": [
    "def prob_target(data):\n",
    "    pos_prob = count_target(data)['1']/sum(count_target(data).values())\n",
    "    neg_prob = count_target(data)['0']/sum(count_target(data).values())\n",
    "    return pos_prob, neg_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:35:17.329601Z",
     "start_time": "2018-09-15T08:35:17.050143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49884666666666666, 0.5011533333333333)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_target(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. likelihood 계산\n",
    "- ## $P(x|y=C_k)$\n",
    "- Laplace Smoothing\n",
    "    - ### $\\frac {N_i + \\alpha}{N+\\alpha K}$\n",
    "    - 매우 작은 값을 추가하여 값이 0이 되지 않도록 한다. \n",
    "    - 여러값의 곱을 취할 경우 하나만 0이되면 전체가 0이 되는 문제가 있기 때문이다.\n",
    "        - ex. '메가박스'라는 단어가 긍정을 표현한 리뷰에만 포함된 경우\n",
    "            - P(메가박스 | C_neg) = 0 이 되므로 P(C_neg | 메가박스) 도 0이 되어버린다.\n",
    "            - 라플라스 스무딩 적용 시, P(메가박스 | C_neg) = k / n+k 가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 단어별 카운트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:36:58.908688Z",
     "start_time": "2018-09-15T08:36:58.903130Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_words(data):\n",
    "    from collections import defaultdict\n",
    "    counts = defaultdict(lambda: [0, 0]) ## value의 기본 자료형이 [0, 0]인 dict\n",
    "    for i, row in enumerate(data):\n",
    "        review_words = row[1].split()\n",
    "        sentiment = row[2]\n",
    "        for word in review_words:\n",
    "            counts[word][0 if sentiment == '1' else 1] += 1 ## word count | C_pos, word count | C_neg\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:37:35.220604Z",
     "start_time": "2018-09-15T08:37:33.377315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 12]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정우성이라는 단어는 긍정에서 몇번, 부정에서 몇번 나왔는지\n",
    "\n",
    "count_words(train)['정우성']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:37:45.676040Z",
     "start_time": "2018-09-15T08:37:45.663195Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'정우성': [16, 12]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## count_words(train)의 결과는 아래와 같은 형태를 가지고 있다. [긍정, 부정]\n",
    "\n",
    "{'정우성' : [16, 12]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 단어별 확률계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:38:12.298164Z",
     "start_time": "2018-09-15T08:38:12.293107Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_probabilities(counts, target, k=1):\n",
    "    \"\"\"laplace smoothing 적용\"\"\"\n",
    "    from collections import defaultdict\n",
    "    probabilities = defaultdict(dict)\n",
    "    total_pos = target['1'] ## 클래스 1의 총 개수\n",
    "    total_neg = target['0'] ## 클래스 0의 총 개수\n",
    "    \n",
    "    for w, (positive, negative) in counts.items():\n",
    "        probabilities[w] = ((positive + k) / (total_pos + k),  ## P(word | C_pos)\n",
    "                            (negative + k) / (total_neg + k))  ## P(word | C_neg)\n",
    "        \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:38:49.334442Z",
     "start_time": "2018-09-15T08:38:46.777916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0002271876837547442, 0.00017293213078990076)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_probabilities(count_words(train), count_target(train))['정우성']\n",
    "# (P(정우성 | y=긍정), P(정우성 | y=부정))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 사후확률 계산\n",
    "- ## $P(y=C_k|x)$\n",
    "- 언더플로우 방지를 위한 log 연산\n",
    "    - 확률 계산 시 확률을 계속 곱해주게되면 매우 낮은 값들이 나와 언더플로우 현상이 발생할 수 있다.\n",
    "    - 이를 방지하기 위해 $P(x∣y=C_{ k })$를 $log(P(x∣y=C_{ k }))$ 로 바꿔서 연산한다. \n",
    "    - ## $log(P(x∣y=C_{ k })) =\\sum _{i=1}^{P}log({P(x_j|y=C_k)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:39:10.860220Z",
     "start_time": "2018-09-15T08:39:10.849487Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentiment_probability(word_probs, prob_target, review):\n",
    "    import math\n",
    "    review_words = review.split()\n",
    "    log_prob_if_neg = log_prob_if_pos = 0.0\n",
    "    pos_prob = prob_target[0]\n",
    "    neg_prob = prob_target[1]\n",
    "    log_each_word_prob = 0\n",
    "    \n",
    "    for word in review_words:\n",
    "        # 단어가 긍정/부정에서 출현할 확률 (likelihood)\n",
    "        \n",
    "        if word in word_probs:\n",
    "            ## 리뷰의 단어가 기존 학습 데이터에 있는 단어일 때\n",
    "            log_prob_if_pos += math.log(word_probs[word][0])\n",
    "            log_prob_if_neg += math.log(word_probs[word][1])\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    prob_if_pos = log_prob_if_pos + math.log(pos_prob) ## log(P(x|C_pos)P(C_pos)) = log(P(x|C_pos)) + log(P(C_pos))\n",
    "    prob_if_neg = log_prob_if_neg + math.log(neg_prob) ## log(P(x|C_neg)P(C_neg)) = log(P(x|C_neg)) + log(P(C_neg))\n",
    "    \n",
    "    return prob_if_pos , prob_if_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:39:56.386685Z",
     "start_time": "2018-09-15T08:39:54.011082Z"
    }
   },
   "outputs": [],
   "source": [
    "word_probs = word_probabilities(count_words(train), count_target(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:39:58.430222Z",
     "start_time": "2018-09-15T08:39:58.168964Z"
    }
   },
   "outputs": [],
   "source": [
    "target_prob = prob_target(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:39:58.558174Z",
     "start_time": "2018-09-15T08:39:58.552089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8544678', '뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아', '0']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:40:10.239438Z",
     "start_time": "2018-09-15T08:40:10.233887Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 리뷰 확률 :  -62.31275723227796 8.66788981205466e-28\n",
      "부정 리뷰 확률 :  -59.9225108890304 9.462026915642333e-27\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "pos_proba, neg_proba = sentiment_probability(word_probs, target_prob, test[2][1])\n",
    "print('긍정 리뷰 확률 : ', pos_proba, math.exp(pos_proba))\n",
    "print('부정 리뷰 확률 : ', neg_proba, math.exp(neg_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:40:10.482371Z",
     "start_time": "2018-09-15T08:40:10.477504Z"
    }
   },
   "outputs": [],
   "source": [
    "# pos_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:43:35.897497Z",
     "start_time": "2018-09-15T08:43:35.879347Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, k = 1):\n",
    "        self.k = k\n",
    "        \n",
    "    def count_target(self, data):\n",
    "        from collections import defaultdict\n",
    "        counts = defaultdict(int)\n",
    "        for i, row in enumerate(data):\n",
    "            sentiment = row[2]\n",
    "            if sentiment == '1':\n",
    "                counts[sentiment] += 1\n",
    "            else:\n",
    "                counts[sentiment] += 1\n",
    "        return counts\n",
    "    \n",
    "    def prob_target(self, data):\n",
    "        pos_prob = self.count_target(data)['1']/sum(self.count_target(data).values())\n",
    "        neg_prob = self.count_target(data)['0']/sum(self.count_target(data).values())\n",
    "        return pos_prob, neg_prob\n",
    "\n",
    "    def count_words(self, data):\n",
    "        from collections import defaultdict\n",
    "        counts = defaultdict(lambda: [0, 0])\n",
    "        for i, row in enumerate(data):\n",
    "            review_words = row[1].split()\n",
    "            sentiment = row[2]\n",
    "            for word in review_words:\n",
    "                counts[word][0 if sentiment == '1' else 1] += 1      \n",
    "        return counts\n",
    "\n",
    "    def word_probabilities(self, counts, target, k=1):\n",
    "        from collections import defaultdict\n",
    "        \"\"\"laplace smoothing 적용\"\"\"\n",
    "        probabilities = defaultdict(dict)\n",
    "        self.total_pos = target['1']\n",
    "        self.total_neg = target['0']\n",
    "        for w, (positive, negative) in counts.items():\n",
    "            probabilities[w] = ((positive + k) / (self.total_pos + k), \n",
    "                                (negative + k) / (self.total_neg + k))\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    def sentiment_probability(self, word_prob, review):\n",
    "        import math\n",
    "        review_words = review.split()\n",
    "        log_prob_if_neg = log_prob_if_pos = 0.0\n",
    "        log_prob_if_not_pos = log_prob_if_not_neg = 0.0\n",
    "        \n",
    "        pos_prob = self.pos_prob\n",
    "        neg_prob = self.neg_prob\n",
    "        \n",
    "        for word in review_words:\n",
    "            if word in word_prob:\n",
    "                ## 리뷰의 단어가 기존 학습 데이터에 있는 단어일 때\n",
    "                log_prob_if_pos += math.log(word_prob[word][0])\n",
    "                log_prob_if_neg += math.log(word_prob[word][1])\n",
    "                \n",
    "            else:\n",
    "                ## 리뷰의 단어가 기존 학습 데이터에 없는 새로운 단어일 때 \n",
    "                log_prob_if_pos += math.log((0 + self.k)/self.total_pos + self.k)\n",
    "                log_prob_if_neg += math.log((0 + self.k)/self.total_neg + self.k)                \n",
    "                \n",
    "        prob_if_pos = log_prob_if_pos + math.log(pos_prob)\n",
    "        prob_if_neg = log_prob_if_neg + math.log(neg_prob)\n",
    "        return prob_if_pos , prob_if_neg\n",
    "  \n",
    "    \n",
    "    def train(self, data):\n",
    "        self.pos_prob, self.neg_prob = self.prob_target(data)\n",
    "        word_counts = self.count_words(data)\n",
    "        target_counts = self.count_target(data)\n",
    "        self.word_prob = self.word_probabilities(word_counts, target_counts, k = self.k)\n",
    "    \n",
    "    def predict(self, review):\n",
    "        prob_if_pos , prob_if_neg = self.sentiment_probability(self.word_prob, review)\n",
    "        if prob_if_pos > prob_if_neg:\n",
    "            return '1'\n",
    "        else:\n",
    "            return '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:43:36.450691Z",
     "start_time": "2018-09-15T08:43:36.446993Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:43:40.782657Z",
     "start_time": "2018-09-15T08:43:37.816436Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier.train(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:43:42.482946Z",
     "start_time": "2018-09-15T08:43:41.743894Z"
    }
   },
   "outputs": [],
   "source": [
    "true_target = []\n",
    "predicted_target = []\n",
    "for i, row in enumerate(test):\n",
    "    true_target.append(row[2])\n",
    "    predicted_target.append(classifier.predict(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:43:43.092813Z",
     "start_time": "2018-09-15T08:43:42.486351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.83      0.81     24827\n",
      "          1       0.82      0.78      0.80     25173\n",
      "\n",
      "avg / total       0.81      0.80      0.80     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(true_target, predicted_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:44:17.025047Z",
     "start_time": "2018-09-15T08:44:16.556373Z"
    }
   },
   "outputs": [],
   "source": [
    "X = list(zip(*train))[1]\n",
    "y = np.array(list(zip(*train))[2], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:44:18.506435Z",
     "start_time": "2018-09-15T08:44:18.333330Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = list(zip(*test))[1]\n",
    "y_test = np.array(list(zip(*test))[2], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:44:19.588479Z",
     "start_time": "2018-09-15T08:44:19.566845Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "## http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "model = Pipeline([\n",
    "            ('vect', CountVectorizer()), \n",
    "            ('mb', MultinomialNB()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:45:35.317292Z",
     "start_time": "2018-09-15T08:45:31.024527Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('mb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:45:39.230130Z",
     "start_time": "2018-09-15T08:45:38.356693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.84      0.83     24827\n",
      "          1       0.84      0.81      0.82     25173\n",
      "\n",
      "avg / total       0.83      0.83      0.83     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:46:15.334991Z",
     "start_time": "2018-09-15T08:46:08.709898Z"
    }
   },
   "outputs": [],
   "source": [
    "## Pipeline 없이 사용\n",
    "\n",
    "vectorizer = CountVectorizer().fit(X)\n",
    "x_vec = vectorizer.transform(X)\n",
    "model = MultinomialNB().fit(x_vec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T08:46:49.393610Z",
     "start_time": "2018-09-15T08:46:48.503929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.84      0.83     24827\n",
      "          1       0.84      0.81      0.82     25173\n",
      "\n",
      "avg / total       0.83      0.83      0.83     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(vectorizer.transform(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
