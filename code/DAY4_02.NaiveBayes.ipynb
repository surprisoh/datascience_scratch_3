{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:18:56.811185Z",
     "start_time": "2018-09-15T05:18:54.800324Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 댓글을 이용한 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:18:56.821546Z",
     "start_time": "2018-09-15T05:18:56.815008Z"
    }
   },
   "outputs": [],
   "source": [
    "# !bitsadmin /transfer get https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt %cd%\\ratings_train.txt\n",
    "# !bitsadmin /transfer get https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt %cd%\\ratings_test.txt    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  mac / linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:19:05.632910Z",
     "start_time": "2018-09-15T05:18:56.826099Z"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n",
    "!wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:19:07.287523Z",
     "start_time": "2018-09-15T05:19:06.787285Z"
    }
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import numpy as np\n",
    "with codecs.open(\"ratings_train.txt\", encoding='utf-8') as f:\n",
    "    train = [line.split('\\t') for line in f.read().splitlines()]\n",
    "    train = train[1:]   # header 제외\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:19:07.527589Z",
     "start_time": "2018-09-15T05:19:07.290667Z"
    }
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"ratings_test.txt\", encoding='utf-8') as f:\n",
    "    test = [line.split('\\t') for line in f.read().splitlines()]\n",
    "    test = test[1:]   # header 제외\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나이브베이즈 모델을 이용한 감성 분석 (Sentiment Analysis)\n",
    "- 네이버 영화 리뷰\n",
    "    - 평점 3점 이상이면 긍정 / 3점 미만이면 부정\n",
    "- 사전확률 계산\n",
    "- likelihood 계산\n",
    "- 모델 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:19:09.282823Z",
     "start_time": "2018-09-15T05:19:09.270316Z"
    }
   },
   "outputs": [],
   "source": [
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:19:10.945341Z",
     "start_time": "2018-09-15T05:19:10.937849Z"
    }
   },
   "outputs": [],
   "source": [
    "test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 사전확률 계산\n",
    "- ## $ P(y = C_k) $\n",
    "    - 각 클래스 (C) 의 확률 계산\n",
    "        - 클래스별 비율을 계산하는 것임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:19:55.967656Z",
     "start_time": "2018-09-15T05:19:55.956721Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_target(data):\n",
    "    from collections import defaultdict\n",
    "    counts = defaultdict(int) ## value의 기본 자료형이 int인 dict\n",
    "    for i, row in enumerate(data):\n",
    "        sentiment = row[2] # 긍정인지, 부정인지\n",
    "        counts[sentiment] += 1\n",
    "            \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:19:56.636328Z",
     "start_time": "2018-09-15T05:19:56.556746Z"
    }
   },
   "outputs": [],
   "source": [
    "count_target(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:20:09.113291Z",
     "start_time": "2018-09-15T05:20:09.107834Z"
    }
   },
   "outputs": [],
   "source": [
    "def prob_target(data):\n",
    "    pos_prob = count_target(data)['1']/sum(count_target(data).values())\n",
    "    neg_prob = count_target(data)['0']/sum(count_target(data).values())\n",
    "    return pos_prob, neg_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:20:10.009498Z",
     "start_time": "2018-09-15T05:20:09.732344Z"
    }
   },
   "outputs": [],
   "source": [
    "prob_target(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. likelihood 계산\n",
    "- ## $P(x|y=C_k)$\n",
    "- Laplace Smoothing\n",
    "    - ### $\\frac {N_i + \\alpha}{N+\\alpha K}$\n",
    "    - 매우 작은 값을 추가하여 값이 0이 되지 않도록 한다. \n",
    "    - 여러값의 곱을 취할 경우 하나만 0이되면 전체가 0이 되는 문제가 있기 때문이다.\n",
    "        - ex. '메가박스'라는 단어가 긍정을 표현한 리뷰에만 포함된 경우\n",
    "            - P(메가박스 | C_neg) = 0 이 되므로 P(C_neg | 메가박스) 도 0이 되어버린다.\n",
    "            - 라플라스 스무딩 적용 시, P(메가박스 | C_neg) = k / n+k 가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 단어별 카운트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:20:40.945750Z",
     "start_time": "2018-09-15T05:20:40.939159Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_words(data):\n",
    "    from collections import defaultdict\n",
    "    counts = defaultdict(lambda: [0, 0]) ## value의 기본 자료형이 [0, 0]인 dict\n",
    "    for i, row in enumerate(data):\n",
    "        review_words = row[1].split()\n",
    "        sentiment = row[2]\n",
    "        for word in review_words:\n",
    "            counts[word][0 if sentiment == '1' else 1] += 1 ## word count | C_pos, word count | C_neg\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:20:43.549062Z",
     "start_time": "2018-09-15T05:20:41.381770Z"
    }
   },
   "outputs": [],
   "source": [
    "# 정우성이라는 단어는 긍정에서 몇번, 부정에서 몇번 나왔는지\n",
    "\n",
    "count_words(train)['정우성']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:20:43.561345Z",
     "start_time": "2018-09-15T05:20:43.553160Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## count_words(train)의 결과는 아래와 같은 형태를 가지고 있다. [긍정, 부정]\n",
    "\n",
    "{'정우성' : [16, 12]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 단어별 확률계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:21:58.188427Z",
     "start_time": "2018-09-15T05:21:58.182292Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_probabilities(counts, target, k=1):\n",
    "    \"\"\"laplace smoothing 적용\"\"\"\n",
    "    from collections import defaultdict\n",
    "    probabilities = defaultdict(dict)\n",
    "    total_pos = target['1'] ## 클래스 1의 총 개수\n",
    "    total_neg = target['0'] ## 클래스 0의 총 개수\n",
    "    \n",
    "    for w, (positive, negative) in counts.items():\n",
    "        probabilities[w] = ((positive + k) / (total_pos + k),  ## P(word | C_pos)\n",
    "                            (negative + k) / (total_neg + k))  ## P(word | C_neg)\n",
    "        \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:22:01.048614Z",
     "start_time": "2018-09-15T05:21:58.511894Z"
    }
   },
   "outputs": [],
   "source": [
    "word_probabilities(count_words(train), count_target(train))['정우성']\n",
    "# (P(정우성 | y=긍정), P(정우성 | y=부정))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 사후확률 계산\n",
    "- ## $P(y=C_k|x)$\n",
    "- 언더플로우 방지를 위한 log 연산\n",
    "    - 확률 계산 시 확률을 계속 곱해주게되면 매우 낮은 값들이 나와 언더플로우 현상이 발생할 수 있다.\n",
    "    - 이를 방지하기 위해 $P(x∣y=C_{ k })$를 $log(P(x∣y=C_{ k }))$ 로 바꿔서 연산한다. \n",
    "    - ## $log(P(x∣y=C_{ k })) =\\sum _{i=1}^{P}log({P(x_j|y=C_k)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:22:36.619100Z",
     "start_time": "2018-09-15T05:22:36.612588Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentiment_probability(word_probs, prob_target, review):\n",
    "    import math\n",
    "    review_words = review.split()\n",
    "    log_prob_if_neg = log_prob_if_pos = 0.0\n",
    "    pos_prob = prob_target[0]\n",
    "    neg_prob = prob_target[1]\n",
    "    log_each_word_prob = 0\n",
    "    \n",
    "    for word in review_words:\n",
    "        # 단어가 긍정/부정에서 출현할 확률 (likelihood)\n",
    "        \n",
    "        if word in word_probs:\n",
    "            ## 리뷰의 단어가 기존 학습 데이터에 있는 단어일 때\n",
    "            log_prob_if_pos += math.log(word_probs[word][0])\n",
    "            log_prob_if_neg += math.log(word_probs[word][1])\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    prob_if_pos = log_prob_if_pos + math.log(pos_prob) ## log(P(x|C_pos)P(C_pos)) = log(P(x|C_pos)) + log(P(C_pos))\n",
    "    prob_if_neg = log_prob_if_neg + math.log(neg_prob) ## log(P(x|C_neg)P(C_neg)) = log(P(x|C_neg)) + log(P(C_neg))\n",
    "    \n",
    "    return prob_if_pos , prob_if_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:22:39.789842Z",
     "start_time": "2018-09-15T05:22:37.586413Z"
    }
   },
   "outputs": [],
   "source": [
    "word_probs = word_probabilities(count_words(train), count_target(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:22:48.244957Z",
     "start_time": "2018-09-15T05:22:47.960057Z"
    }
   },
   "outputs": [],
   "source": [
    "target_prob = prob_target(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:22:48.707091Z",
     "start_time": "2018-09-15T05:22:48.699511Z"
    }
   },
   "outputs": [],
   "source": [
    "test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:22:49.160148Z",
     "start_time": "2018-09-15T05:22:49.150694Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "pos_proba, neg_proba = sentiment_probability(word_probs, target_prob, test[2][1])\n",
    "print('긍정 리뷰 확률 : ', pos_proba, math.exp(pos_proba))\n",
    "print('부정 리뷰 확률 : ', neg_proba, math.exp(neg_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:23:05.320192Z",
     "start_time": "2018-09-15T05:23:05.292353Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, k = 1):\n",
    "        self.k = k\n",
    "        \n",
    "    def count_target(self, data):\n",
    "        from collections import defaultdict\n",
    "        counts = defaultdict(int)\n",
    "        for i, row in enumerate(data):\n",
    "            sentiment = row[2]\n",
    "            if sentiment == '1':\n",
    "                counts[sentiment] += 1\n",
    "            else:\n",
    "                counts[sentiment] += 1\n",
    "        return counts\n",
    "    \n",
    "    def prob_target(self, data):\n",
    "        pos_prob = self.count_target(data)['1']/sum(self.count_target(data).values())\n",
    "        neg_prob = self.count_target(data)['0']/sum(self.count_target(data).values())\n",
    "        return pos_prob, neg_prob\n",
    "\n",
    "    def count_words(self, data):\n",
    "        from collections import defaultdict\n",
    "        counts = defaultdict(lambda: [0, 0])\n",
    "        for i, row in enumerate(data):\n",
    "            review_words = row[1].split()\n",
    "            sentiment = row[2]\n",
    "            for word in review_words:\n",
    "                counts[word][0 if sentiment == '1' else 1] += 1      \n",
    "        return counts\n",
    "\n",
    "    def word_probabilities(self, counts, target, k=1):\n",
    "        from collections import defaultdict\n",
    "        \"\"\"laplace smoothing 적용\"\"\"\n",
    "        probabilities = defaultdict(dict)\n",
    "        self.total_pos = target['1']\n",
    "        self.total_neg = target['0']\n",
    "        for w, (positive, negative) in counts.items():\n",
    "            probabilities[w] = ((positive + k) / (self.total_pos + k), \n",
    "                                (negative + k) / (self.total_neg + k))\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    def sentiment_probability(self, word_prob, review):\n",
    "        import math\n",
    "        review_words = review.split()\n",
    "        log_prob_if_neg = log_prob_if_pos = 0.0\n",
    "        log_prob_if_not_pos = log_prob_if_not_neg = 0.0\n",
    "        \n",
    "        pos_prob = self.pos_prob\n",
    "        neg_prob = self.neg_prob\n",
    "        \n",
    "        for word in review_words:\n",
    "            if word in word_prob:\n",
    "                ## 리뷰의 단어가 기존 학습 데이터에 있는 단어일 때\n",
    "                log_prob_if_pos += math.log(word_prob[word][0])\n",
    "                log_prob_if_neg += math.log(word_prob[word][1])\n",
    "                \n",
    "            else:\n",
    "                ## 리뷰의 단어가 기존 학습 데이터에 없는 새로운 단어일 때 \n",
    "                log_prob_if_pos += math.log((0 + self.k)/self.total_pos + self.k)\n",
    "                log_prob_if_neg += math.log((0 + self.k)/self.total_neg + self.k)                \n",
    "                \n",
    "        prob_if_pos = log_prob_if_pos + math.log(pos_prob)\n",
    "        prob_if_neg = log_prob_if_neg + math.log(neg_prob)\n",
    "        return prob_if_pos , prob_if_neg\n",
    "  \n",
    "    \n",
    "    def train(self, data):\n",
    "        self.pos_prob, self.neg_prob = self.prob_target(data)\n",
    "        word_counts = self.count_words(data)\n",
    "        target_counts = self.count_target(data)\n",
    "        self.word_prob = self.word_probabilities(word_counts, target_counts, k = self.k)\n",
    "    \n",
    "    def predict(self, review):\n",
    "        prob_if_pos , prob_if_neg = self.sentiment_probability(self.word_prob, review)\n",
    "        if prob_if_pos > prob_if_neg:\n",
    "            return '1'\n",
    "        else:\n",
    "            return '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:23:06.110886Z",
     "start_time": "2018-09-15T05:23:06.103632Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:23:09.791609Z",
     "start_time": "2018-09-15T05:23:06.518169Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier.train(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:23:10.649485Z",
     "start_time": "2018-09-15T05:23:09.794830Z"
    }
   },
   "outputs": [],
   "source": [
    "true_target = []\n",
    "predicted_target = []\n",
    "for i, row in enumerate(test):\n",
    "    true_target.append(row[2])\n",
    "    predicted_target.append(classifier.predict(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:23:10.743881Z",
     "start_time": "2018-09-15T05:23:10.652273Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(true_target, predicted_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:23:15.200960Z",
     "start_time": "2018-09-15T05:23:14.725073Z"
    }
   },
   "outputs": [],
   "source": [
    "X = list(zip(*train))[1]\n",
    "y = np.array(list(zip(*train))[2], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:23:15.391974Z",
     "start_time": "2018-09-15T05:23:15.204074Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = list(zip(*test))[1]\n",
    "y_test = np.array(list(zip(*test))[2], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:23:15.427724Z",
     "start_time": "2018-09-15T05:23:15.399047Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "## http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "model = Pipeline([\n",
    "            ('vect', CountVectorizer()), \n",
    "            ('mb', MultinomialNB()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:23:20.196550Z",
     "start_time": "2018-09-15T05:23:15.434832Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:23:21.329116Z",
     "start_time": "2018-09-15T05:23:20.202212Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:23:29.359919Z",
     "start_time": "2018-09-15T05:23:21.332988Z"
    }
   },
   "outputs": [],
   "source": [
    "## Pipeline 없이 사용\n",
    "\n",
    "vectorizer = CountVectorizer().fit(X)\n",
    "x_vec = vectorizer.transform(X)\n",
    "model = MultinomialNB().fit(x_vec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T05:23:30.348453Z",
     "start_time": "2018-09-15T05:23:29.363434Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, model.predict(vectorizer.transform(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
